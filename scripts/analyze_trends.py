#!/usr/bin/env python3
"""
å†å²è¶‹åŠ¿åˆ†æå·¥å…·

åˆ†æè¿‡å» 30 å¤©çš„æµ‹è¯•æ•°æ®ï¼Œç”Ÿæˆè¶‹åŠ¿æŠ¥å‘Šï¼š
- æµ‹è¯•é€šè¿‡ç‡è¶‹åŠ¿
- é«˜é¢‘å¤±è´¥ç”¨ä¾‹æ’è¡Œ
- ä¸åŒåœ°åŒºçš„æµ‹è¯•æˆåŠŸç‡å¯¹æ¯”
- æ€§èƒ½æŒ‡æ ‡è¶‹åŠ¿
"""

import json
import statistics
from pathlib import Path
from typing import Dict, List, Tuple
from datetime import datetime, timedelta
from collections import defaultdict, Counter
import argparse


class TrendAnalyzer:
    """å†å²è¶‹åŠ¿åˆ†æå™¨"""

    def __init__(
        self,
        reports_dir: str = "reports",
        days: int = 30,
        output_file: str = "reports/trend_analysis.json"
    ):
        """
        åˆå§‹åŒ–è¶‹åŠ¿åˆ†æå™¨

        Args:
            reports_dir: æµ‹è¯•æŠ¥å‘Šç›®å½•
            days: åˆ†æçš„å¤©æ•°
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        self.reports_dir = Path(reports_dir)
        self.days = days
        self.output_file = Path(output_file)

    def _load_test_reports(self) -> List[Dict]:
        """
        åŠ è½½æµ‹è¯•æŠ¥å‘Š

        Returns:
            æµ‹è¯•æŠ¥å‘Šåˆ—è¡¨ï¼ŒæŒ‰æ—¶é—´æ’åº
        """
        reports = []

        # åŠ è½½æœ€è¿‘ N å¤©çš„æŠ¥å‘Š
        cutoff_date = datetime.now() - timedelta(days=self.days)

        # æŸ¥æ‰¾æ‰€æœ‰æµ‹è¯•ç»“æœæ–‡ä»¶
        result_files = list(self.reports_dir.glob("**/test_results.json"))

        for result_file in result_files:
            try:
                with open(result_file) as f:
                    data = json.load(f)

                # è§£ææ—¶é—´æˆ³
                timestamp_str = data.get('timestamp', '')
                if timestamp_str:
                    timestamp = datetime.fromisoformat(timestamp_str.replace('Z', '+00:00'))

                    # åªä¿ç•™æœ€è¿‘ N å¤©çš„æ•°æ®
                    if timestamp >= cutoff_date:
                        reports.append({
                            'timestamp': timestamp,
                            'data': data
                        })
            except (json.JSONDecodeError, ValueError) as e:
                print(f"âš ï¸ è·³è¿‡æ— æ•ˆæŠ¥å‘Š: {result_file} ({e})")
                continue

        # æŒ‰æ—¶é—´æ’åº
        reports.sort(key=lambda x: x['timestamp'])

        return reports

    def _calculate_pass_rate_trend(self, reports: List[Dict]) -> Dict:
        """
        è®¡ç®—æµ‹è¯•é€šè¿‡ç‡è¶‹åŠ¿

        Args:
            reports: æµ‹è¯•æŠ¥å‘Šåˆ—è¡¨

        Returns:
            é€šè¿‡ç‡è¶‹åŠ¿æ•°æ®
        """
        daily_stats = defaultdict(lambda: {'passed': 0, 'failed': 0, 'total': 0})

        for report in reports:
            date = report['timestamp'].date()
            data = report['data']

            summary = data.get('summary', {})
            passed = summary.get('passed', 0)
            failed = summary.get('failed', 0)

            daily_stats[date]['passed'] += passed
            daily_stats[date]['failed'] += failed
            daily_stats[date]['total'] += passed + failed

        # è®¡ç®—æ¯æ—¥é€šè¿‡ç‡
        trend_data = []
        for date in sorted(daily_stats.keys()):
            stats = daily_stats[date]
            pass_rate = (stats['passed'] / stats['total'] * 100) if stats['total'] > 0 else 0

            trend_data.append({
                'date': date.isoformat(),
                'passed': stats['passed'],
                'failed': stats['failed'],
                'total': stats['total'],
                'pass_rate': round(pass_rate, 2)
            })

        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        pass_rates = [d['pass_rate'] for d in trend_data]

        return {
            'data': trend_data,
            'statistics': {
                'average_pass_rate': round(statistics.mean(pass_rates), 2) if pass_rates else 0,
                'min_pass_rate': min(pass_rates) if pass_rates else 0,
                'max_pass_rate': max(pass_rates) if pass_rates else 0,
                'std_deviation': round(statistics.stdev(pass_rates), 2) if len(pass_rates) > 1 else 0,
                'trend': self._calculate_trend(pass_rates)
            }
        }

    def _calculate_trend(self, values: List[float]) -> str:
        """
        è®¡ç®—è¶‹åŠ¿æ–¹å‘

        Args:
            values: æ•°å€¼åˆ—è¡¨

        Returns:
            è¶‹åŠ¿æè¿°: 'improving', 'stable', 'declining'
        """
        if not values or len(values) < 2:
            return 'stable'

        # è®¡ç®—å‰åŠå’ŒååŠçš„å¹³å‡å€¼
        mid = len(values) // 2
        first_half_avg = statistics.mean(values[:mid])
        second_half_avg = statistics.mean(values[mid:])

        diff = second_half_avg - first_half_avg

        if diff > 2:  # æå‡è¶…è¿‡ 2%
            return 'improving'
        elif diff < -2:  # ä¸‹é™è¶…è¿‡ 2%
            return 'declining'
        else:
            return 'stable'

    def _analyze_frequent_failures(self, reports: List[Dict]) -> Dict:
        """
        åˆ†æé«˜é¢‘å¤±è´¥ç”¨ä¾‹

        Args:
            reports: æµ‹è¯•æŠ¥å‘Šåˆ—è¡¨

        Returns:
            é«˜é¢‘å¤±è´¥åˆ†ææ•°æ®
        """
        failure_counter = Counter()
        failure_details = defaultdict(lambda: {
            'count': 0,
            'product_name': '',
            'error_types': Counter(),
            'first_seen': None,
            'last_seen': None
        })

        for report in reports:
            data = report['data']
            timestamp = report['timestamp']

            # ç»Ÿè®¡å¤±è´¥çš„æµ‹è¯•
            for test in data.get('tests', []):
                if test.get('status') == 'failed':
                    product_id = test.get('product_id', 'unknown')
                    error_type = test.get('error_type', 'unknown')

                    failure_counter[product_id] += 1

                    # è®°å½•è¯¦ç»†ä¿¡æ¯
                    details = failure_details[product_id]
                    details['count'] += 1
                    details['product_name'] = test.get('product_name', product_id)
                    details['error_types'][error_type] += 1

                    if details['first_seen'] is None:
                        details['first_seen'] = timestamp
                    details['last_seen'] = timestamp

        # ç”Ÿæˆæ’è¡Œæ¦œ
        top_failures = []
        for product_id, count in failure_counter.most_common(20):
            details = failure_details[product_id]

            # è®¡ç®—å¤±è´¥å¤©æ•°
            if details['first_seen'] and details['last_seen']:
                failure_days = (details['last_seen'] - details['first_seen']).days + 1
            else:
                failure_days = 1

            # ä¸»è¦é”™è¯¯ç±»å‹
            main_error_type = details['error_types'].most_common(1)[0][0] if details['error_types'] else 'unknown'

            top_failures.append({
                'product_id': product_id,
                'product_name': details['product_name'],
                'failure_count': count,
                'failure_days': failure_days,
                'main_error_type': main_error_type,
                'error_types': dict(details['error_types']),
                'first_seen': details['first_seen'].isoformat() if details['first_seen'] else None,
                'last_seen': details['last_seen'].isoformat() if details['last_seen'] else None
            })

        return {
            'total_unique_failures': len(failure_counter),
            'top_failures': top_failures
        }

    def _analyze_regional_performance(self, reports: List[Dict]) -> Dict:
        """
        åˆ†æä¸åŒåœ°åŒºçš„æµ‹è¯•æˆåŠŸç‡

        Args:
            reports: æµ‹è¯•æŠ¥å‘Šåˆ—è¡¨

        Returns:
            åœ°åŒºæ€§èƒ½åˆ†ææ•°æ®
        """
        regional_stats = defaultdict(lambda: {'passed': 0, 'failed': 0, 'total': 0})

        for report in reports:
            data = report['data']

            # ç»Ÿè®¡æ¯ä¸ªåœ°åŒºçš„æµ‹è¯•ç»“æœ
            for test in data.get('tests', []):
                region = test.get('region', 'unknown')
                status = test.get('status', 'unknown')

                regional_stats[region]['total'] += 1

                if status == 'passed':
                    regional_stats[region]['passed'] += 1
                elif status == 'failed':
                    regional_stats[region]['failed'] += 1

        # è®¡ç®—æ¯ä¸ªåœ°åŒºçš„æˆåŠŸç‡
        regional_performance = []
        for region, stats in regional_stats.items():
            pass_rate = (stats['passed'] / stats['total'] * 100) if stats['total'] > 0 else 0

            regional_performance.append({
                'region': region,
                'total_tests': stats['total'],
                'passed': stats['passed'],
                'failed': stats['failed'],
                'pass_rate': round(pass_rate, 2)
            })

        # æŒ‰é€šè¿‡ç‡æ’åº
        regional_performance.sort(key=lambda x: x['pass_rate'], reverse=True)

        return {
            'total_regions': len(regional_performance),
            'regions': regional_performance
        }

    def _analyze_performance_trends(self, reports: List[Dict]) -> Dict:
        """
        åˆ†ææ€§èƒ½æŒ‡æ ‡è¶‹åŠ¿

        Args:
            reports: æµ‹è¯•æŠ¥å‘Šåˆ—è¡¨

        Returns:
            æ€§èƒ½è¶‹åŠ¿æ•°æ®
        """
        daily_performance = defaultdict(lambda: {
            'page_load_times': [],
            'api_response_times': []
        })

        for report in reports:
            date = report['timestamp'].date()
            data = report['data']

            # æ”¶é›†æ€§èƒ½æ•°æ®
            for test in data.get('tests', []):
                metrics = test.get('metrics', {})

                page_load_time = metrics.get('page_load_time')
                if page_load_time:
                    daily_performance[date]['page_load_times'].append(page_load_time)

                api_response_time = metrics.get('api_response_time')
                if api_response_time:
                    daily_performance[date]['api_response_times'].append(api_response_time)

        # è®¡ç®—æ¯æ—¥å¹³å‡æ€§èƒ½
        performance_data = []
        for date in sorted(daily_performance.keys()):
            perf = daily_performance[date]

            avg_page_load = statistics.mean(perf['page_load_times']) if perf['page_load_times'] else 0
            avg_api_response = statistics.mean(perf['api_response_times']) if perf['api_response_times'] else 0

            performance_data.append({
                'date': date.isoformat(),
                'avg_page_load_time': round(avg_page_load, 2),
                'avg_api_response_time': round(avg_api_response, 2),
                'test_count': len(perf['page_load_times'])
            })

        # è®¡ç®—è¶‹åŠ¿
        page_load_times = [d['avg_page_load_time'] for d in performance_data if d['avg_page_load_time'] > 0]
        api_response_times = [d['avg_api_response_time'] for d in performance_data if d['avg_api_response_time'] > 0]

        return {
            'data': performance_data,
            'statistics': {
                'avg_page_load_time': round(statistics.mean(page_load_times), 2) if page_load_times else 0,
                'avg_api_response_time': round(statistics.mean(api_response_times), 2) if api_response_times else 0,
                'page_load_trend': self._calculate_trend(page_load_times) if page_load_times else 'stable',
                'api_response_trend': self._calculate_trend(api_response_times) if api_response_times else 'stable'
            }
        }

    def _identify_periodic_issues(self, reports: List[Dict]) -> Dict:
        """
        è¯†åˆ«å‘¨æœŸæ€§é—®é¢˜

        Args:
            reports: æµ‹è¯•æŠ¥å‘Šåˆ—è¡¨

        Returns:
            å‘¨æœŸæ€§é—®é¢˜åˆ†æ
        """
        # æŒ‰æ˜ŸæœŸå‡ ç»Ÿè®¡å¤±è´¥ç‡
        weekday_stats = defaultdict(lambda: {'passed': 0, 'failed': 0, 'total': 0})

        for report in reports:
            weekday = report['timestamp'].strftime('%A')  # Monday, Tuesday, etc.
            data = report['data']

            summary = data.get('summary', {})
            passed = summary.get('passed', 0)
            failed = summary.get('failed', 0)

            weekday_stats[weekday]['passed'] += passed
            weekday_stats[weekday]['failed'] += failed
            weekday_stats[weekday]['total'] += passed + failed

        # è®¡ç®—æ¯ä¸ªæ˜ŸæœŸçš„å¤±è´¥ç‡
        weekday_performance = []
        weekday_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']

        for weekday in weekday_order:
            if weekday in weekday_stats:
                stats = weekday_stats[weekday]
                failure_rate = (stats['failed'] / stats['total'] * 100) if stats['total'] > 0 else 0

                weekday_performance.append({
                    'weekday': weekday,
                    'total_tests': stats['total'],
                    'failed': stats['failed'],
                    'failure_rate': round(failure_rate, 2)
                })

        # æ‰¾å‡ºå¤±è´¥ç‡æœ€é«˜çš„æ—¥å­
        highest_failure_day = max(weekday_performance, key=lambda x: x['failure_rate']) if weekday_performance else None

        return {
            'weekday_performance': weekday_performance,
            'highest_failure_day': highest_failure_day
        }

    def analyze(self) -> Dict:
        """
        æ‰§è¡Œå®Œæ•´çš„è¶‹åŠ¿åˆ†æ

        Returns:
            è¶‹åŠ¿åˆ†ææŠ¥å‘Š
        """
        print(f"ğŸ“Š æ­£åœ¨åˆ†æè¿‡å» {self.days} å¤©çš„æµ‹è¯•æ•°æ®...")

        # åŠ è½½æµ‹è¯•æŠ¥å‘Š
        reports = self._load_test_reports()

        if not reports:
            print("âš ï¸ æœªæ‰¾åˆ°æµ‹è¯•æŠ¥å‘Šæ•°æ®")
            return {
                'error': 'No test reports found',
                'reports_dir': str(self.reports_dir),
                'days': self.days
            }

        print(f"âœ… å·²åŠ è½½ {len(reports)} ä¸ªæµ‹è¯•æŠ¥å‘Š")

        # æ‰§è¡Œå„é¡¹åˆ†æ
        print("ğŸ” åˆ†ææµ‹è¯•é€šè¿‡ç‡è¶‹åŠ¿...")
        pass_rate_trend = self._calculate_pass_rate_trend(reports)

        print("ğŸ” åˆ†æé«˜é¢‘å¤±è´¥ç”¨ä¾‹...")
        frequent_failures = self._analyze_frequent_failures(reports)

        print("ğŸ” åˆ†æåœ°åŒºæ€§èƒ½...")
        regional_performance = self._analyze_regional_performance(reports)

        print("ğŸ” åˆ†ææ€§èƒ½è¶‹åŠ¿...")
        performance_trends = self._analyze_performance_trends(reports)

        print("ğŸ” è¯†åˆ«å‘¨æœŸæ€§é—®é¢˜...")
        periodic_issues = self._identify_periodic_issues(reports)

        # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        report = {
            'generated_at': datetime.now().isoformat(),
            'analysis_period': {
                'days': self.days,
                'start_date': reports[0]['timestamp'].isoformat() if reports else None,
                'end_date': reports[-1]['timestamp'].isoformat() if reports else None,
                'total_reports': len(reports)
            },
            'pass_rate_trend': pass_rate_trend,
            'frequent_failures': frequent_failures,
            'regional_performance': regional_performance,
            'performance_trends': performance_trends,
            'periodic_issues': periodic_issues,
            'insights': self._generate_insights(
                pass_rate_trend,
                frequent_failures,
                regional_performance,
                performance_trends,
                periodic_issues
            )
        }

        return report

    def _generate_insights(
        self,
        pass_rate_trend: Dict,
        frequent_failures: Dict,
        regional_performance: Dict,
        performance_trends: Dict,
        periodic_issues: Dict
    ) -> List[Dict]:
        """
        ç”Ÿæˆæ´å¯Ÿå»ºè®®

        Args:
            pass_rate_trend: é€šè¿‡ç‡è¶‹åŠ¿
            frequent_failures: é«˜é¢‘å¤±è´¥
            regional_performance: åœ°åŒºæ€§èƒ½
            performance_trends: æ€§èƒ½è¶‹åŠ¿
            periodic_issues: å‘¨æœŸæ€§é—®é¢˜

        Returns:
            æ´å¯Ÿåˆ—è¡¨
        """
        insights = []

        # 1. é€šè¿‡ç‡è¶‹åŠ¿æ´å¯Ÿ
        trend = pass_rate_trend['statistics']['trend']
        avg_pass_rate = pass_rate_trend['statistics']['average_pass_rate']

        if trend == 'improving':
            insights.append({
                'type': 'positive',
                'category': 'pass_rate',
                'message': f'æµ‹è¯•é€šè¿‡ç‡å‘ˆä¸Šå‡è¶‹åŠ¿ï¼Œå¹³å‡é€šè¿‡ç‡ {avg_pass_rate}%',
                'priority': 'info'
            })
        elif trend == 'declining':
            insights.append({
                'type': 'warning',
                'category': 'pass_rate',
                'message': f'æµ‹è¯•é€šè¿‡ç‡å‘ˆä¸‹é™è¶‹åŠ¿ï¼Œå¹³å‡é€šè¿‡ç‡ {avg_pass_rate}%ï¼Œéœ€è¦å…³æ³¨',
                'priority': 'high'
            })

        if avg_pass_rate < 90:
            insights.append({
                'type': 'warning',
                'category': 'pass_rate',
                'message': f'å¹³å‡é€šè¿‡ç‡ {avg_pass_rate}% ä½äºç›®æ ‡å€¼ 90%',
                'priority': 'high'
            })

        # 2. é«˜é¢‘å¤±è´¥æ´å¯Ÿ
        top_failures = frequent_failures.get('top_failures', [])
        if top_failures:
            top_failure = top_failures[0]
            insights.append({
                'type': 'action_required',
                'category': 'frequent_failures',
                'message': f'æœ€é«˜é¢‘å¤±è´¥å•†å“: {top_failure["product_name"]} ({top_failure["failure_count"]} æ¬¡å¤±è´¥)',
                'data': top_failure,
                'priority': 'high'
            })

            # æ£€æŸ¥æ˜¯å¦æœ‰é•¿æœŸå­˜åœ¨çš„é—®é¢˜
            chronic_failures = [f for f in top_failures if f['failure_days'] > 7]
            if chronic_failures:
                insights.append({
                    'type': 'warning',
                    'category': 'frequent_failures',
                    'message': f'{len(chronic_failures)} ä¸ªå•†å“å­˜åœ¨æŒç»­ 7 å¤©ä»¥ä¸Šçš„å¤±è´¥é—®é¢˜',
                    'priority': 'high'
                })

        # 3. åœ°åŒºæ€§èƒ½æ´å¯Ÿ
        regions = regional_performance.get('regions', [])
        if regions:
            # æ‰¾å‡ºä½é€šè¿‡ç‡åœ°åŒº
            low_pass_regions = [r for r in regions if r['pass_rate'] < 90]
            if low_pass_regions:
                insights.append({
                    'type': 'action_required',
                    'category': 'regional',
                    'message': f'{len(low_pass_regions)} ä¸ªåœ°åŒºé€šè¿‡ç‡ä½äº 90%: {", ".join([r["region"] for r in low_pass_regions[:3]])}',
                    'priority': 'medium'
                })

        # 4. æ€§èƒ½è¶‹åŠ¿æ´å¯Ÿ
        perf_stats = performance_trends.get('statistics', {})
        page_load_trend = perf_stats.get('page_load_trend', 'stable')
        avg_page_load = perf_stats.get('avg_page_load_time', 0)

        if page_load_trend == 'declining':  # æ€§èƒ½ä¸‹é™ï¼ˆåŠ è½½æ—¶é—´å¢åŠ ï¼‰
            insights.append({
                'type': 'warning',
                'category': 'performance',
                'message': f'é¡µé¢åŠ è½½æ—¶é—´å‘ˆä¸Šå‡è¶‹åŠ¿ï¼Œå¹³å‡ {avg_page_load}sï¼Œéœ€è¦ä¼˜åŒ–',
                'priority': 'medium'
            })

        if avg_page_load > 3:
            insights.append({
                'type': 'action_required',
                'category': 'performance',
                'message': f'å¹³å‡é¡µé¢åŠ è½½æ—¶é—´ {avg_page_load}s è¶…è¿‡ 3 ç§’é˜ˆå€¼',
                'priority': 'medium'
            })

        # 5. å‘¨æœŸæ€§é—®é¢˜æ´å¯Ÿ
        highest_failure_day = periodic_issues.get('highest_failure_day')
        if highest_failure_day and highest_failure_day['failure_rate'] > 10:
            insights.append({
                'type': 'warning',
                'category': 'periodic',
                'message': f'æ¯å‘¨ {highest_failure_day["weekday"]} å¤±è´¥ç‡æœ€é«˜ ({highest_failure_day["failure_rate"]}%)ï¼Œå»ºè®®é¿å…åœ¨è¯¥æ—¶é—´éƒ¨ç½²',
                'priority': 'medium'
            })

        return insights

    def save_report(self, report: Dict):
        """
        ä¿å­˜è¶‹åŠ¿åˆ†ææŠ¥å‘Š

        Args:
            report: è¶‹åŠ¿åˆ†ææŠ¥å‘Š
        """
        self.output_file.parent.mkdir(parents=True, exist_ok=True)

        with open(self.output_file, 'w') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)

        print(f"ğŸ’¾ è¶‹åŠ¿åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {self.output_file}")

    def print_report(self, report: Dict):
        """
        æ‰“å°è¶‹åŠ¿åˆ†ææŠ¥å‘Šæ‘˜è¦

        Args:
            report: è¶‹åŠ¿åˆ†ææŠ¥å‘Š
        """
        print("\n" + "=" * 70)
        print("ğŸ“ˆ å†å²è¶‹åŠ¿åˆ†ææŠ¥å‘Š")
        print("=" * 70)

        # åˆ†æå‘¨æœŸ
        period = report['analysis_period']
        print(f"\nğŸ“… åˆ†æå‘¨æœŸ: {period['days']} å¤© ({period['total_reports']} ä¸ªæŠ¥å‘Š)")

        # é€šè¿‡ç‡è¶‹åŠ¿
        pass_rate = report['pass_rate_trend']['statistics']
        trend_emoji = {
            'improving': 'ğŸ“ˆ',
            'stable': 'â¡ï¸',
            'declining': 'ğŸ“‰'
        }
        print(f"\nâœ… æµ‹è¯•é€šè¿‡ç‡:")
        print(f"  å¹³å‡é€šè¿‡ç‡: {pass_rate['average_pass_rate']}%")
        print(f"  è¶‹åŠ¿: {trend_emoji.get(pass_rate['trend'], 'â¡ï¸')} {pass_rate['trend']}")

        # é«˜é¢‘å¤±è´¥
        failures = report['frequent_failures']
        print(f"\nâŒ é«˜é¢‘å¤±è´¥å•†å“ (Top 5):")
        for failure in failures['top_failures'][:5]:
            print(f"  - {failure['product_name']}: {failure['failure_count']} æ¬¡å¤±è´¥ ({failure['failure_days']} å¤©)")

        # åœ°åŒºæ€§èƒ½
        regions = report['regional_performance']['regions']
        print(f"\nğŸŒ åœ°åŒºæ€§èƒ½ (Top 5):")
        for region in regions[:5]:
            print(f"  - {region['region']}: {region['pass_rate']}% ({region['total_tests']} ä¸ªæµ‹è¯•)")

        # æ´å¯Ÿå»ºè®®
        insights = report.get('insights', [])
        if insights:
            print(f"\nğŸ’¡ å…³é”®æ´å¯Ÿ:")
            for insight in insights[:5]:
                emoji = {
                    'positive': 'âœ…',
                    'warning': 'âš ï¸',
                    'action_required': 'ğŸš¨'
                }
                print(f"  {emoji.get(insight['type'], 'â€¢')} {insight['message']}")

        print("\n" + "=" * 70)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='å†å²è¶‹åŠ¿åˆ†æ')
    parser.add_argument(
        '--reports-dir',
        default='reports',
        help='æµ‹è¯•æŠ¥å‘Šç›®å½•'
    )
    parser.add_argument(
        '--days',
        type=int,
        default=30,
        help='åˆ†æçš„å¤©æ•°ï¼ˆé»˜è®¤ 30 å¤©ï¼‰'
    )
    parser.add_argument(
        '--output',
        default='reports/trend_analysis.json',
        help='è¾“å‡ºæ–‡ä»¶è·¯å¾„'
    )
    parser.add_argument(
        '--json',
        action='store_true',
        help='è¾“å‡º JSON æ ¼å¼'
    )

    args = parser.parse_args()

    analyzer = TrendAnalyzer(
        reports_dir=args.reports_dir,
        days=args.days,
        output_file=args.output
    )

    # æ‰§è¡Œåˆ†æ
    report = analyzer.analyze()

    # ä¿å­˜æŠ¥å‘Š
    analyzer.save_report(report)

    # æ‰“å°æŠ¥å‘Š
    if args.json:
        print(json.dumps(report, indent=2, ensure_ascii=False))
    else:
        analyzer.print_report(report)


if __name__ == '__main__':
    main()
