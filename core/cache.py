"""
å•†å“çˆ¬è™«ç¼“å­˜æ¨¡å—

æä¾›å•†å“æ•°æ®ç¼“å­˜åŠŸèƒ½ï¼Œé¿å…é‡å¤çˆ¬å–ï¼Œæå‡æ€§èƒ½ã€‚
"""

import json
import hashlib
from pathlib import Path
from datetime import datetime, timedelta
from typing import Optional, Dict, Any


class CrawlerCache:
    """çˆ¬è™«ç¼“å­˜ç®¡ç†å™¨"""

    def __init__(
        self,
        cache_dir: str = "data/cache",
        ttl_hours: int = 24
    ):
        """
        åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨

        Args:
            cache_dir: ç¼“å­˜ç›®å½•
            ttl_hours: ç¼“å­˜æœ‰æ•ˆæœŸï¼ˆå°æ—¶ï¼‰
        """
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self.ttl = timedelta(hours=ttl_hours)
        self.metadata_file = self.cache_dir / "cache_metadata.json"
        self.metadata = self._load_metadata()

    def _load_metadata(self) -> Dict:
        """åŠ è½½ç¼“å­˜å…ƒæ•°æ®"""
        if self.metadata_file.exists():
            with open(self.metadata_file) as f:
                return json.load(f)
        return {}

    def _save_metadata(self):
        """ä¿å­˜ç¼“å­˜å…ƒæ•°æ®"""
        with open(self.metadata_file, 'w') as f:
            json.dump(self.metadata, f, indent=2)

    def _get_cache_key(self, url: str) -> str:
        """
        ç”Ÿæˆç¼“å­˜é”®

        Args:
            url: å•†å“ URL

        Returns:
            ç¼“å­˜é”®ï¼ˆURL çš„ MD5 å“ˆå¸Œï¼‰
        """
        return hashlib.md5(url.encode()).hexdigest()

    def _get_cache_path(self, cache_key: str) -> Path:
        """è·å–ç¼“å­˜æ–‡ä»¶è·¯å¾„"""
        return self.cache_dir / f"{cache_key}.json"

    def _is_expired(self, cache_key: str) -> bool:
        """
        æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ

        Args:
            cache_key: ç¼“å­˜é”®

        Returns:
            æ˜¯å¦è¿‡æœŸ
        """
        if cache_key not in self.metadata:
            return True

        cached_time = datetime.fromisoformat(
            self.metadata[cache_key]['cached_at']
        )
        return datetime.now() - cached_time > self.ttl

    def get(self, url: str) -> Optional[Dict[str, Any]]:
        """
        ä»ç¼“å­˜è·å–æ•°æ®

        Args:
            url: å•†å“ URL

        Returns:
            ç¼“å­˜çš„å•†å“æ•°æ®ï¼Œå¦‚æœä¸å­˜åœ¨æˆ–å·²è¿‡æœŸåˆ™è¿”å› None
        """
        cache_key = self._get_cache_key(url)
        cache_path = self._get_cache_path(cache_key)

        # æ£€æŸ¥ç¼“å­˜æ˜¯å¦å­˜åœ¨ä¸”æœªè¿‡æœŸ
        if not cache_path.exists() or self._is_expired(cache_key):
            return None

        # è¯»å–ç¼“å­˜æ•°æ®
        try:
            with open(cache_path) as f:
                data = json.load(f)

            # æ›´æ–°è®¿é—®æ—¶é—´
            self.metadata[cache_key]['last_accessed'] = datetime.now().isoformat()
            self._save_metadata()

            print(f"âœ… ç¼“å­˜å‘½ä¸­: {url}")
            return data

        except Exception as e:
            print(f"âš ï¸ è¯»å–ç¼“å­˜å¤±è´¥: {e}")
            return None

    def set(self, url: str, data: Dict[str, Any]):
        """
        ä¿å­˜æ•°æ®åˆ°ç¼“å­˜

        Args:
            url: å•†å“ URL
            data: å•†å“æ•°æ®
        """
        cache_key = self._get_cache_key(url)
        cache_path = self._get_cache_path(cache_key)

        # ä¿å­˜æ•°æ®
        try:
            with open(cache_path, 'w') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)

            # æ›´æ–°å…ƒæ•°æ®
            self.metadata[cache_key] = {
                'url': url,
                'cached_at': datetime.now().isoformat(),
                'last_accessed': datetime.now().isoformat(),
                'size_bytes': cache_path.stat().st_size
            }
            self._save_metadata()

            print(f"ğŸ’¾ å·²ç¼“å­˜: {url}")

        except Exception as e:
            print(f"âš ï¸ ä¿å­˜ç¼“å­˜å¤±è´¥: {e}")

    def clear(self, url: Optional[str] = None):
        """
        æ¸…é™¤ç¼“å­˜

        Args:
            url: å¦‚æœæŒ‡å®šï¼Œä»…æ¸…é™¤è¯¥ URL çš„ç¼“å­˜ï¼›å¦åˆ™æ¸…é™¤æ‰€æœ‰ç¼“å­˜
        """
        if url:
            # æ¸…é™¤å•ä¸ªç¼“å­˜
            cache_key = self._get_cache_key(url)
            cache_path = self._get_cache_path(cache_key)

            if cache_path.exists():
                cache_path.unlink()

            if cache_key in self.metadata:
                del self.metadata[cache_key]
                self._save_metadata()

            print(f"ğŸ—‘ï¸ å·²æ¸…é™¤ç¼“å­˜: {url}")

        else:
            # æ¸…é™¤æ‰€æœ‰ç¼“å­˜
            for cache_file in self.cache_dir.glob("*.json"):
                if cache_file.name != "cache_metadata.json":
                    cache_file.unlink()

            self.metadata = {}
            self._save_metadata()

            print("ğŸ—‘ï¸ å·²æ¸…é™¤æ‰€æœ‰ç¼“å­˜")

    def cleanup_expired(self):
        """æ¸…ç†è¿‡æœŸçš„ç¼“å­˜"""
        expired_keys = []

        for cache_key in list(self.metadata.keys()):
            if self._is_expired(cache_key):
                cache_path = self._get_cache_path(cache_key)
                if cache_path.exists():
                    cache_path.unlink()
                expired_keys.append(cache_key)

        for key in expired_keys:
            del self.metadata[key]

        if expired_keys:
            self._save_metadata()
            print(f"ğŸ—‘ï¸ å·²æ¸…ç† {len(expired_keys)} ä¸ªè¿‡æœŸç¼“å­˜")

    def get_stats(self) -> Dict:
        """
        è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯

        Returns:
            ç¼“å­˜ç»Ÿè®¡æ•°æ®
        """
        total_size = sum(
            meta.get('size_bytes', 0)
            for meta in self.metadata.values()
        )

        expired_count = sum(
            1 for key in self.metadata.keys()
            if self._is_expired(key)
        )

        return {
            'total_items': len(self.metadata),
            'total_size_mb': total_size / (1024 * 1024),
            'expired_items': expired_count,
            'valid_items': len(self.metadata) - expired_count,
            'cache_dir': str(self.cache_dir),
            'ttl_hours': self.ttl.total_seconds() / 3600
        }

    def print_stats(self):
        """æ‰“å°ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.get_stats()

        print("\nğŸ“Š ç¼“å­˜ç»Ÿè®¡:")
        print(f"  æ€»ç¼“å­˜é¡¹: {stats['total_items']}")
        print(f"  æœ‰æ•ˆç¼“å­˜: {stats['valid_items']}")
        print(f"  è¿‡æœŸç¼“å­˜: {stats['expired_items']}")
        print(f"  æ€»å¤§å°: {stats['total_size_mb']:.2f} MB")
        print(f"  æœ‰æ•ˆæœŸ: {stats['ttl_hours']} å°æ—¶")
        print(f"  ç¼“å­˜ç›®å½•: {stats['cache_dir']}")
